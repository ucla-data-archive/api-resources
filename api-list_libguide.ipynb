{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_extra_fields = ['limitations', 'how-its-accessed', 'how-to-register', 'result-format', 'contact-for-technical-questions', 'what-it-does']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#UCB\n",
    "\n",
    "# Using the Requests Library to make a GET request \n",
    "req = requests.get('https://guides.lib.berkeley.edu/information-studies/apis')\n",
    "\n",
    "# read the content of the server's response\n",
    "src = req.text\n",
    "\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "# Grab all the links in the s-lg-content-74224 div enclosed in paragraphs\n",
    "links = soup.select(\"#s-lg-content-74224 p a\")\n",
    "\n",
    "\n",
    "# For each link, print the link text, the href value, \n",
    "# and walk several elements forward to what is usually the description\n",
    "\n",
    "list_of_rows = []\n",
    "\n",
    "for link in links:\n",
    "    row_dict = {}\n",
    "    row_dict['name'] = link.text\n",
    "    row_dict['for-more-information'] = link.attrs[\"href\"]\n",
    "    row_dict['source'] = 'UCB'\n",
    "    for field in mit_extra_fields:\n",
    "        row_dict[field] = ''\n",
    "    list_of_rows.append(row_dict)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UCSD \n",
    "\n",
    "# Using the Requests Library to make a GET request \n",
    "req = requests.get('https://ucsd.libguides.com/data-statistics/apis')\n",
    "\n",
    "# read the content of the server's response\n",
    "src = req.text\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "# Grab all the links in the s-lg-content-74224 div enclosed in paragraphs\n",
    "links = soup.select(\"#s-lg-link-list-49042253 li a\")\n",
    "\n",
    "\n",
    "# For each link, print the link text, the href value, \n",
    "# and walk several elements forward to what is usually the description\n",
    "\n",
    "\n",
    "for link in links:\n",
    "    row_dict = {}\n",
    "    row_dict['name'] = link.text\n",
    "    row_dict['for-more-information'] = link.attrs[\"href\"]\n",
    "    row_dict['source'] = 'UCSD'\n",
    "    for field in mit_extra_fields:\n",
    "        row_dict[field] = ''\n",
    "    list_of_rows.append(row_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT \n",
    "\n",
    "# Using the Requests Library to make a GET request \n",
    "req = requests.get('https://libraries.mit.edu/scholarly/publishing/apis-for-scholarly-resources')\n",
    "\n",
    "# read the content of the server's response\n",
    "src = req.text\n",
    "\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "# Grab all expandable sections\n",
    "sections = soup.find_all(class_=\"expandable\")\n",
    "\n",
    "\n",
    "# For each link, print the link text, the href value, \n",
    "# and walk several elements forward to what is usually the description\n",
    "\n",
    "# For each  (expandable) section:\n",
    "#  For each paragraph (p tag):\n",
    "#   Grab the text between <strong>, this is the key\n",
    "#   Grab remaining text, this is the value\n",
    "\n",
    "num_of_apis = []\n",
    "\n",
    "for section in sections:\n",
    "    header = section.find('h3')\n",
    "\n",
    "    paragraphs = section.find_all('p')\n",
    "    \n",
    "    row_dict = {}\n",
    "    row_dict = {'name' : header.text}\n",
    "    row_dict['source'] = 'MIT'\n",
    "    \n",
    "    for paragraph in paragraphs:\n",
    "        \n",
    "        key = paragraph.find('strong')\n",
    "        text_of_cell = paragraph.text\n",
    "        \n",
    "        value = text_of_cell.replace(key.text, '')\n",
    "        key_without_colon = key.text.replace(':', '')\n",
    "\n",
    "        # Need to convert cell text to header friendly format\n",
    "        # Remove punctuation, case, and convert white space to dash\n",
    "        \n",
    "        clean_key = key.text.translate(str.maketrans('', '', string.punctuation))\n",
    "        clean_key = clean_key.strip()\n",
    "        clean_key = clean_key.replace('â€™', '')\n",
    "        clean_key = clean_key.replace('\\xa0', ' ')\n",
    "        clean_key = clean_key.replace(' ', '-')\n",
    "        clean_key = clean_key.lower()\n",
    "        \n",
    "        clean_value = value.strip()\n",
    "        clean_value = clean_value.replace('\\xa0', ' ')\n",
    "        row_dict[clean_key] = clean_value\n",
    "    \n",
    "    list_of_rows.append(row_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "csv_columns = list(list_of_rows[0].keys())\n",
    "csv_columns.extend(('what-they-do', 'how-theyre-accessed', 'notable-included-apis'))\n",
    "\n",
    "csv_file = \"urls.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in list_of_rows:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
